{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2916d0",
   "metadata": {},
   "source": [
    "# **PROJECT SYNTHESIS & RETROSPECTIVE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde44144",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a9f878",
   "metadata": {},
   "source": [
    "## **1. Project Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed05e789",
   "metadata": {},
   "source": [
    "### **Bối cảnh và Cách tiếp cận**\n",
    "\n",
    "Đồ án này tập trung giải quyết bài toán dự báo mưa tại Úc – một lục địa có mức độ đa dạng khí hậu rất cao, nơi các quy luật khí tượng mang tính tổng quát thường không đủ khả năng mô tả chính xác các biến động địa phương. Trước bối cảnh đó, đồ án được triển khai theo một quy trình khoa học dữ liệu có cấu trúc rõ ràng, gồm năm giai đoạn liên tiếp: thu thập dữ liệu, khám phá dữ liệu, xác định vấn đề, phân tích và diễn giải kết quả.\n",
    "\n",
    "Thay vì chỉ dừng lại ở các thống kê mô tả hoặc tối ưu hóa mô hình thuần túy, đồ án áp dụng chiến lược phân tích đa tầng, trong đó trọng tâm là kiểm định các giả thuyết dựa trên cơ chế vật lý. Cách tiếp cận này cho phép kết hợp chặt chẽ kiến thức miền về khí tượng – thủy văn với các kỹ thuật phân tích dữ liệu hiện đại, nhằm đảm bảo rằng các kết luận rút ra không chỉ có ý nghĩa thống kê mà còn phù hợp với bản chất vật lý của các quá trình khí quyển."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a35611f",
   "metadata": {},
   "source": [
    "### **Phạm vi đồ án và Kết quả cốt lõi**\n",
    "\n",
    "Lộ trình phân tích của dự án được định hướng bởi sáu câu hỏi nghiên cứu (RQ1 – RQ6), được tổ chức thành hai trụ cột chính. Trụ cột thứ nhất tập trung vào việc làm rõ các cơ chế vật lý chi phối quá trình hình thành mưa, bao gồm vai trò của động lực học áp suất (RQ1), ảnh hưởng của tính mùa vụ (RQ2), tương tác giữa trạng thái nhiệt và độ ẩm (RQ3), cũng như các tín hiệu động lực học gió (RQ4). Trụ cột thứ hai hướng đến tối ưu hóa khía cạnh kỹ thuật dữ liệu, cụ thể là chiến lược xử lý dữ liệu thiếu (RQ5) và thiết kế, đánh giá các mô hình học máy trong bối cảnh dữ liệu mất cân bằng nghiêm trọng (RQ6).\n",
    "\n",
    "Các kết quả then chốt cho thấy rằng các tín hiệu dự báo mưa tại Úc không tồn tại dưới dạng những quy luật phổ quát áp dụng đồng nhất cho mọi khu vực. Ngược lại, hiệu lực của chúng phụ thuộc mạnh mẽ và phi tuyến vào bối cảnh nhiệt – ẩm của khí quyển, cũng như đặc điểm địa lý của từng vùng, đặc biệt là sự khác biệt căn bản giữa khu vực ven biển và nội địa. Phát hiện này nhấn mạnh tầm quan trọng của các cách tiếp cận dự báo thích ứng theo ngữ cảnh, thay vì các mô hình \"một công thức cho mọi nơi\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e922e7d",
   "metadata": {},
   "source": [
    "## **2. Key Findings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfa75f4",
   "metadata": {},
   "source": [
    "### **Insight 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87cf797",
   "metadata": {},
   "source": [
    "Sự giảm áp suất chỉ cho thấy rằng khí quyển đang có nhiễu động, nhưng chưa đủ để gây mưa. Độ ẩm mới là yếu tố quyết định cuối cùng.\n",
    "Nếu không khí quá khô (điển hình ở vùng hoang mạc hoặc đồng cỏ), thì dù áp suất có giảm mạnh, mưa vẫn khó xảy ra. Trong trường hợp này, tín hiệu áp suất giảm chỉ phản ánh các dao động nhiệt khô của khí quyển, chứ không phải là dấu hiệu của một quá trình tạo mưa thực sự. \n",
    "\n",
    "Nói cách khác, áp suất giảm chỉ \"có ý nghĩa\" khi độ ẩm đủ cao; nếu không, đó chỉ là một tín hiệu gây hiểu lầm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70a21e",
   "metadata": {},
   "source": [
    "### **Insight 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ec760",
   "metadata": {},
   "source": [
    "\"Bộ đôi chỉ báo vàng\" – Độ ẩm 3 giờ chiều (tương quan thuận mạnh nhất $\\approx$ 0.45) và Thời lượng nắng (tương quan nghịch mạnh nhất ~ -0.44) là hai biến số nhạy bén nhất, cho phép nhận diện sớm sự thay đổi trạng thái khí quyển trước khi mưa xảy ra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d998a9",
   "metadata": {},
   "source": [
    "### **Insight 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb38fc1d",
   "metadata": {},
   "source": [
    "\"Hiệu ứng chăn ẩm\" – Biên độ nhiệt ngày (DTR) hẹp là một bộ lọc vật lý quan trọng; khi DTR kết hợp với thời lượng nắng thấp, xác suất mưa bùng nổ lên trên 75%, chứng minh rằng mây giữ nhiệt ban đêm là tiền đề then chốt cho kết tủa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788cc6b",
   "metadata": {},
   "source": [
    "### **Insight 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b818540",
   "metadata": {},
   "source": [
    "Tại vùng ven biển, khi thời tiết khô ráo, gió mạnh và đổi hướng thường chỉ là kết quả của hoàn lưu gió đất – gió biển. Những hiện tượng này xảy ra thường xuyên và không nhất thiết dẫn đến mưa, nên tín hiệu gió trong bối cảnh này dễ tạo ra báo động giả.\n",
    "\n",
    "Ngược lại, tại vùng nội địa, nơi không khí thường rất khô và mưa hiếm khi xảy ra, thì tình huống hoàn toàn khác. Ở đây, nếu vẫn quan sát thấy gió giật rất mạnh kèm theo sự đổi hướng đột ngột, điều đó cho thấy khí quyển đang trải qua một nhiễu động cực kỳ mạnh. Chỉ những hệ thống đối lưu rất dữ dội mới có thể tạo ra tín hiệu như vậy và đồng thời vượt qua được rào cản khô hạn để hình thành mưa.\n",
    "\n",
    "Vì vậy, tại nội địa, cùng một tín hiệu gió lại trở thành dấu hiệu đáng tin cậy của các hiện tượng thời tiết nguy hiểm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af47768",
   "metadata": {},
   "source": [
    "### **Insight 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e206c3",
   "metadata": {},
   "source": [
    "Mô hình hồi quy đa biến (Iterative Imputer hay thuật toán MICE) có khả năng tái tạo lại mối quan hệ nhân quả tự nhiên từ những điểm dữ liệu bị thiếu (ví dụ như nhiệt độ cao kết hợp với độ ẩm thấp có thể dẫn đến lượng bốc hơi nhiều), đảm bảo dữ liệu sau khi xử lý vẫn tuân theo các quy luật tự nhiên vốn có."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac2dfe",
   "metadata": {},
   "source": [
    "### **Insight 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc8435",
   "metadata": {},
   "source": [
    "Đôi khi việc chuyển dịch trọng tâm từ một mô hình học máy chính xác về mặt toán học sang một mô hình có trách nhiệm về mặt thực tế thông qua việc xác định kiến trúc thuật toán tối ưu để giải mã các tín hiệu hiếm của thời tiết nhưng có tác động vô cùng lớn lại đóng vai trò rất quan trọng trong quản trị rủi ro thiên tai. Trong đó khả năng hạn chế bỏ sót (Recall) chính là thước đo thực sự của một hệ thống dự báo thời tiết hữu dụng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e968330",
   "metadata": {},
   "source": [
    "## **3. Limitations**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c31c62",
   "metadata": {},
   "source": [
    "Mặc dù bài làm đã làm sáng tỏ nhiều cơ chế quan trọng liên quan đến quá trình hình thành mưa tại Úc, nhóm thừa nhận rằng các kết quả vẫn chịu ảnh hưởng bởi những giới hạn cố hữu của dữ liệu và phương pháp phân tích. Việc nhận diện rõ các hạn chế này không chỉ giúp diễn giải kết quả một cách thận trọng hơn, mà còn định hướng rõ ràng cho các cải tiến trong các dự án tiếp theo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747625f",
   "metadata": {},
   "source": [
    "### **3.1. Hạn chế liên quan đến dữ liệu (Dataset constraints)**\n",
    "\n",
    "**Dữ liệu quan trắc điểm và thiếu thông tin không gian:**\n",
    "Tập dữ liệu *weatherAUS* được xây dựng từ các trạm quan trắc cố định, trong khi mưa là hiện tượng có tính không gian cao và phân bố rất cục bộ. Việc không có dữ liệu radar hoặc vệ tinh đi kèm làm phát sinh nguy cơ sai lệch nhãn, đặc biệt là các trường hợp mưa xảy ra gần trạm nhưng không được ghi nhận. Điều này có thể dẫn đến các mẫu *false negatives*, từ đó ảnh hưởng đến quá trình huấn luyện và đánh giá mô hình.\n",
    "\n",
    "**Độ phân giải thời gian hạn chế:**\n",
    "Khoảng thời gian quan trắc 6 giờ (9am – 3pm) là quá thưa để phản ánh đầy đủ các biến động nhanh của các hệ thống dông nhiệt, vốn thường hình thành và suy yếu trong vòng 1 – 2 giờ. Ngoài ra, việc thiếu dữ liệu tại các thời điểm chuyển giao trong ngày (như chiều tối hoặc ban đêm) tạo ra độ trễ thông tin, khiến mô hình có thể bỏ sót các tín hiệu kích hoạt mưa xuất hiện muộn.\n",
    "\n",
    "**Thiếu thông tin theo chiều thẳng đứng của khí quyển:**\n",
    "Nghiên cứu chủ yếu dựa trên các biến quan trắc bề mặt, trong khi nhiều cơ chế nền tảng của mưa đối lưu – như độ bất ổn khí quyển (CAPE/CIN), cấu trúc gió tầng cao hay dòng xiết – không được đưa vào phân tích. Sự thiếu vắng dữ liệu thám không hạn chế khả năng giải thích đầy đủ các quá trình vật lý chi phối đối lưu sâu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b73ac78",
   "metadata": {},
   "source": [
    "### **3.2. Hạn chế về phương pháp phân tích (Methodological constraints)**\n",
    "\n",
    "**Giả định tuyến tính trong giai đoạn thăm dò:**\n",
    "Việc sử dụng các chỉ số tương quan tuyến tính như Pearson trong giai đoạn đầu chỉ cung cấp cái nhìn sơ bộ và chưa phản ánh hết bản chất phi tuyến, có ngưỡng của mối quan hệ giữa các biến nhiệt – ẩm và mưa. Một số chỉ số, chẳng hạn như biên độ nhiệt ngày (DTR), mang tính \"hậu nghiệm\" (ex-post), chỉ có thể tính toán sau khi ngày quan trắc kết thúc, do đó hạn chế giá trị ứng dụng trong các bài toán dự báo thời gian thực nếu không sử dụng các giá trị trễ.\n",
    "\n",
    "**Khả năng khái quát hóa chưa tối ưu:**\n",
    "Các mô hình học máy hiện tại sử dụng một bộ tham số chung cho toàn lãnh thổ Úc. Cách tiếp cận này có thể làm suy giảm các tín hiệu đặc thù của từng vùng khí hậu, đặc biệt là sự khác biệt rõ rệt giữa khu vực ven biển và nội địa. Việc phát triển các mô hình chuyên biệt theo tiểu vùng khí hậu có tiềm năng cải thiện đáng kể độ chính xác và khả năng diễn giải.\n",
    "\n",
    "**Giới hạn của kỹ thuật điền khuyết dữ liệu:**\n",
    "Mặc dù phương pháp điền khuyết đa biến (MICE) giúp bảo toàn cấu trúc tương quan tốt hơn so với các phương pháp đơn giản, nó vẫn không thể khôi phục hoàn toàn độ biến thiên tự nhiên của dữ liệu. Một phần các giá trị cực đoan hiếm gặp – vốn đóng vai trò quan trọng trong việc nhận diện các hiện tượng thời tiết nguy hiểm – có thể đã bị làm \"mềm hóa\", từ đó làm giảm độ nhạy của mô hình đối với các sự kiện hiếm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685d7162",
   "metadata": {},
   "source": [
    "### **3.3. Hạn chế về phạm vi nghiên cứu (Scope limitations)**\n",
    "\n",
    "Nghiên cứu tập trung vào các biến số thời tiết ở quy mô ngày và trung quy mô, trong khi chưa xét đến tác động điều biến của các dao động khí hậu quy mô lớn như ENSO (El Niño/La Niña) hay Indian Ocean Dipole. Những hiện tượng vĩ mô này có khả năng làm thay đổi nền tảng mối quan hệ giữa áp suất, gió và mưa theo chu kỳ nhiều năm, và việc chưa đưa chúng vào mô hình giới hạn khả năng tổng quát hóa kết quả trong bối cảnh biến đổi khí hậu dài hạn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54340239",
   "metadata": {},
   "source": [
    "## **4. Future Directions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7587df",
   "metadata": {},
   "source": [
    "Để nâng cao giá trị thực tiễn của hệ thống dự báo, nhóm đề xuất thêm 1 số hướng đi trong tương lai mà đáng nghiên cứu nhằm đi sâu vào bản chất của các hiện tượng thời tiết thay vì chỉ dừng lại ở bài toán dự báo nhị phân (Mưa/Không mưa) đơn thuần.\n",
    "### **4.1. Tính phụ thuộc thời gian và Dự báo chuỗi (Temporal Dynamics)**\n",
    "Một hướng đi thú vị đầu tiên nhóm tập trung vào việc phá vỡ giả định về các điểm dữ liệu độc lập để khai thác bản chất liên tục của các hiện tượng khí quyển, tập trung vào câu hỏi nghiên cứu như sau: \"Làm thế nào để tích hợp lịch sử biến động khí tượng của nhiều ngày liên tiếp nhằm nhận diện các tín hiệu tích lũy, thay vì chỉ dựa vào dữ liệu 'tĩnh' của ngày hôm nay?\".\n",
    "\n",
    "Các phân tích chuyên sâu mà nhóm đề xuất tiến hành để hiểu rõ cách thời gian ảnh hưởng đến khả năng mưa nằm ở việc thực hiện các phân tích chuỗi thời gian (Time-series Analysis) đặc thù:\n",
    "* Phân tích Autocorrelation - ACF và PACF: Xác định độ trễ (lag) hiệu quả. Ví dụ: Liệu độ ẩm của 3 ngày trước hay 7 ngày trước có tác động mạnh nhất đến khả năng mưa hôm nay? Điều này giúp xác định look-back window tối ưu cho mô hình.\n",
    "* Phân tích Tương quan chéo (Cross-correlation): Nghiên cứu xem sự thay đổi của một biến (ví dụ như áp suất) ở thời điểm $t-3$ ảnh hưởng thế nào đến lượng mưa ở thời điểm $t$. Điều này giúp phát hiện các tín hiệu sớm (leading indicators) mà các mô hình thông thường dễ bỏ sót.\n",
    "* Phân tích Phân rã chuỗi thời gian (Seasonal Decomposition): Tách biệt dữ liệu thành 3 thành phần: Xu hướng (Trend), Mùa vụ (Seasonality), và Nhiễu (Residual). Việc này giúp mô hình không bị \"đánh lừa\" bởi các biến động mang tính chu kỳ lặp lại hàng năm.\n",
    "\n",
    "Để quy trình phân tích mang lại hiệu quả tốt nhất, thay vì sử dụng các thuật toán học máy cho dữ liệu bảng (Tabular), chúng ta nên chuyển sang các kiến trúc chuyên dụng cho dữ liệu chuỗi như sau:\n",
    "* Mạng nơ-ron hồi quy (LSTM/GRU): Sử dụng các đơn vị nhớ để lưu lại các trạng thái thời tiết quan trọng từ quá khứ. LSTM đặc biệt mạnh trong việc nhận diện các đợt thời tiết (weather spells) kéo dài.\n",
    "* Kỹ thuật Cửa sổ trượt (Sliding Window Engineering): Tạo ra các đặc trưng thống kê trong một khoảng thời gian như `Humidity_Rolling_Mean_3D` (Trung bình độ ẩm 3 ngày gần nhất) và `Pressure_Trend_Slope` (Độ dốc của đường biểu diễn áp suất trong 5 ngày để thể hiện áp suất đang giảm nhanh hay chậm)\n",
    "* Mô hình CNN-LSTM: Sử dụng CNN để trích xuất đặc trưng không gian và LSTM để xử lý biến đổi thời gian, tạo ra một hệ thống dự báo không-thời gian (Spatio-temporal) phức hợp.\n",
    "\n",
    "Ngoài ra, để phục vụ cho các phân tích chuyên sâu như trên, có thể bổ sung thêm một số nguồn dữ liệu bên lề, tập trung ở 3 loại:\n",
    "* Dữ liệu chuỗi lịch sử dài hạn (Long-term Historical Data): Các chỉ số dao động khí hậu như ENSO (El Niño-Southern Oscillation) hoặc IOD (Indian Ocean Dipole). Đây là các chu kỳ kéo dài hàng tháng/hàng năm ảnh hưởng trực tiếp đến các đợt hạn hán hoặc mưa lũ tại Úc.\n",
    "* Dữ liệu quan trắc theo giờ (High-frequency Observations): Thay vì chỉ có 2 mốc 9am/3pm, dữ liệu theo từng giờ sẽ cho phép mô hình học được \"độ dốc\" của sự thay đổi nhiệt độ và áp suất một cách mịn màng hơn.\n",
    "* Dữ liệu chuỗi ảnh vệ tinh: Các chuỗi video hoặc ảnh hồng ngoại về sự di chuyển của các khối mây (Cloud motion vectors) để mô hình hóa hướng đi của mưa một cách trực quan.\n",
    "\n",
    "Hướng đi này nhóm nhận định có thể mở ra 1 số cải tiến đáng kể:\n",
    "* Dự báo đa bước (Multi-step Ahead Forecasting): Mở rộng hệ thống để dự báo xác suất mưa không chỉ cho ngày mai mà cho cả một tuần tiếp theo (7-day forecast). Điều này đòi hỏi mô hình phải học được sự suy giảm của độ chính xác theo thời gian.\n",
    "* Dự báo sự kiện (Event-based Forecasting): Thay vì dự báo từng ngày riêng lẻ, mô hình sẽ dự báo về thời điểm bắt đầu và thời gian kéo dài của một đợt mưa lớn. Điều này có ý nghĩa cực lớn trong việc lập kế hoạch thoát nước và quản lý giao thông đô thị.\n",
    "* Hệ thống cập nhật động (Online Learning): Cải tiến mô hình để nó có thể tự cập nhật (Retrain) ngay khi nhận được dữ liệu của ngày hôm nay, giúp mô hình luôn thích nghi được với các biến đổi khí hậu bất thường hiện nay.\n",
    "\n",
    "### **4.2. Phân loại mức độ cực đoan (Severity Classification)**\n",
    "Hướng đi tiếp theo này tập trung vào việc chuyển đổi mô hình từ dự báo \"có/không\" sang hệ thống phân cấp mức độ nguy hiểm, giúp tối ưu hóa công tác ứng phó với thiên tai. Cốt lõi của hướng đi gói gọn trong việc thực hiện giải quyết bài toán nghiên cứu: \"Làm thế nào để xây dựng một mô hình phân loại đa lớp (Multi-class) có khả năng nhận diện chính xác các cấp độ mưa (Mưa nhỏ, Mưa vừa, Mưa lớn, Mưa cực đoan) trong bối cảnh dữ liệu bị mất cân bằng nghiêm trọng ở các lớp rủi ro cao?\".\n",
    "\n",
    "Để phục vụ cho hệ thống dự báo mưa cực đoan đòi hỏi hiểu rõ ranh giới giữa mưa lớn thông thường và thiên tai, phần phân tích chuyên sâu phục vụ cho giải quyết bài toán này tập trung ở 3 điểm:\n",
    "* Phân tích Ma trận nhầm lẫn đa lớp (Multi-class Confusion Matrix Analysis): Phân tích xem mô hình thường nhầm lẫn giữa các lớp kế cận nào (ví dụ như nhầm \"Mưa lớn\" thành \"Mưa vừa\"). Đặc biệt chú trọng vào tỷ lệ Miss Rate của lớp \"Mưa cực đoan\", vì đây là sai sót gây hậu quả nghiêm trọng nhất.\n",
    "* Phân tích ngưỡng giới hạn vật lý (Physical Threshold Analysis): Nghiên cứu sự kết hợp của các biến số tại các thời điểm xảy ra mưa cực đoan trong lịch sử. Ví dụ: Xác định sự kết hợp giữa gió giật (WindGustSpeed) cực mạnh và áp suất (Pressure3pm) giảm sâu có phải là đặc trưng của các trận mưa gây lụt lội hay không.\n",
    "* Phân tích chi phí sai số không đối xứng (Asymmetric Cost Analysis): Định lượng hóa thiệt hại. Việc dự báo nhầm một trận mưa cực đoan thành mưa vừa có hậu quả về kinh tế và tính mạng lớn hơn gấp nhiều lần so với chiều ngược lại.\n",
    "\n",
    "Việc phân loại mức độ mưa không phải cho ra kết quả là các lớp độc lập mà cần có tính thứ tự (Ordinal), do đó cần các phương pháp chuyên biệt như:\n",
    "* Hồi quy thứ tự (Ordinal Regression): Sử dụng các thuật toán như Ordered Logit hoặc Proportional Odds Model. Các mô hình này hiểu rằng khoảng cách giữa \"Mưa nhỏ\" và \"Mưa vừa\" có tính logic về mặt cường độ, giúp cải thiện độ chính xác hơn là phân loại đa lớp thông thường.\n",
    "* Hàm mất mát tiêu điểm (Focal Loss): Thay vì dùng Cross-Entropy thông thường, Focal Loss sẽ tập trung phạt mô hình nặng hơn khi dự báo sai các lớp hiếm (Mưa cực đoan), buộc mô hình phải học các đặc trưng khó của lớp rủi ro cao.\n",
    "* Cấu trúc phân tầng (Hierarchical Classification): \n",
    "    * Tầng 1: Dự báo có mưa hay không.\n",
    "    * Tầng 2: Nếu có mưa, dự báo là mưa bình thường hay mưa cực đoan.\n",
    "    * Tầng 3: Chia nhỏ mức độ cực đoan. Cách tiếp cận này giúp giảm áp lực cho mô hình khi phải đối mặt với quá nhiều lớp cùng lúc.\n",
    "\n",
    "Tất nhiên, để bắt được các biến cố cực đoan, dữ liệu mặt đất là chưa đủ mà cần thêm một số nguồn dữ liệu như:\n",
    "* Chỉ số bất ổn định khí quyển (Instability Indices): Các chỉ số như CAPE (Convective Available Potential Energy) hoặc Lifted Index từ dữ liệu thám không (Radiosonde). Các chỉ số này đo lường năng lượng tiềm tàng trong không khí, 1 đặc trưng thể hiện cho các trận mưa cực đoan.\n",
    "* Dữ liệu Radar và Vệ tinh (Brightness Temperature): Nhiệt độ đỉnh mây từ ảnh vệ tinh hồng ngoại giúp xác định độ cao và cường độ của các khối mây đối lưu gây mưa lớn.\n",
    "* Dữ liệu thiệt hại lịch sử (Flood Damage Reports): Kết nối dữ liệu khí tượng với dữ liệu thực địa về ngập lụt để xác thực xem ngưỡng mưa bao nhiêu thì thực sự mang lại tính chất cực đoan cho hạ tầng địa phương.\n",
    "\n",
    "Khả năng mở rộng và cải tiến của hướng đi này mang lại 1 số ý nghĩa quan trọng:\n",
    "* Xây dựng hệ thống cảnh báo sớm dựa trên ngưỡng (Impact-based Forecasting): Chuyển từ bài toán \"Dự báo thời tiết sẽ thế nào\" sang bài toán \"Thời tiết sẽ gây ra tác động gì\". Mô hình sẽ phát tin cảnh báo dựa trên khả năng gây ngập úng của từng cấp độ mưa đối với từng khu vực cụ thể.\n",
    "* Cải tiến bằng Ensemble đặc biệt: Xây dựng một nhóm mô hình (Ensemble) mà trong đó có các mô hình thành phần được huấn luyện chuyên biệt chỉ để tìm ra các trận mưa cực đoan (Expert Models).\n",
    "* Tích hợp học máy với mô hình vật lý (Physics-informed ML): Sử dụng các phương trình nhiệt động lực học làm ràng buộc cho mô hình học máy, đảm bảo rằng các dự báo về mưa cực đoan không vi phạm các định luật bảo toàn năng lượng và khối lượng trong tự nhiên."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c95c52",
   "metadata": {},
   "source": [
    "## **5. Individual Reflections**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ec24a",
   "metadata": {},
   "source": [
    "### **Lê Hà Thanh Chương**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7881b07c",
   "metadata": {},
   "source": [
    "#### **Challenges & Difficulties Encountered**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db1d4f3",
   "metadata": {},
   "source": [
    "Trong suốt quá trình thực hiện dự án, thách thức lớn nhất tôi đối mặt không nằm ở cú pháp lập trình hay việc triển khai mô hình, mà xuất phát từ các rào cản khái niệm và kỹ thuật khi chuyển hóa dữ liệu quan trắc thô thành các chỉ số có ý nghĩa vật lý và khả năng diễn giải khoa học. Đối với Câu hỏi 1, khó khăn nổi bật nằm ở khâu kiến trúc dữ liệu không gian và xử lý dữ liệu thiếu. Tập dữ liệu gốc chỉ cung cấp tên trạm quan trắc mà không đi kèm tọa độ địa lý hay nhãn khí hậu, buộc tôi phải thủ công hóa quá trình phân lớp địa lý. Cụ thể, tôi đã phải đối chiếu vị trí của 49 trạm trên bản đồ khí hậu Úc để gán nhãn chính xác cho từng đới khí hậu và phân loại ven biển – nội địa. Bước này đòi hỏi độ chính xác cao, bởi chỉ một sai lệch nhỏ trong việc gán nhãn cũng có thể làm méo mó toàn bộ các kiểm định vùng miền ở các bước phân tích tiếp theo.\n",
    "\n",
    "Bên cạnh đó, bài toán xử lý dữ liệu thiếu cũng đặt ra thách thức đáng kể. Tôi nhanh chóng nhận ra rằng các phương pháp điền khuyết đơn giản như trung bình toàn cục là không phù hợp, do chúng xóa nhòa cấu trúc mùa vụ và làm suy giảm tính toàn vẹn vật lý của dữ liệu khí tượng. Để khắc phục, tôi đã xây dựng một chiến lược điền khuyết dựa trên ngữ cảnh kết hợp giữa vùng địa lý và mùa vụ, nhằm đảm bảo rằng các giá trị được ước lượng vẫn phản ánh đúng điều kiện môi trường thực tế. Ở cấp độ khái niệm, một khó khăn quan trọng là từ bỏ tư duy tìm kiếm một \"ngưỡng vàng\" phổ quát, đặc biệt đối với biến áp suất. Dữ liệu liên tục cho thấy rằng không tồn tại một giá trị $\\Delta P$ duy nhất có thể dự báo mưa cho mọi khu vực, buộc tôi phải chấp nhận rằng áp suất chỉ đóng vai trò điều kiện cần, trong khi độ ẩm mới là yếu tố điều tiết mang tính quyết định.\n",
    "\n",
    "Những thách thức tương tự tiếp tục xuất hiện ở các câu hỏi nghiên cứu sau, đặc biệt trong việc xử lý dữ liệu hướng gió và phân tích tương tác phi tuyến. Dữ liệu hướng gió (`WindGustDir`) là dữ liệu dạng vòng tròn, trong đó 0° và 360° là tương đương, khiến các phép toán đại số thông thường trở nên không hợp lệ. Việc xây dựng hàm tính khoảng cách góc ngắn nhất đòi hỏi tôi phải tìm hiểu sâu về thống kê định hướng để tránh các sai lệch logic nghiêm trọng. Ở khía cạnh phân tích, một điểm nghẽn về nhận thức xuất hiện khi các kiểm định tương quan tuyến tính ban đầu cho kết quả rất yếu tại vùng nội địa. Thay vì coi đây là dấu hiệu của dữ liệu kém chất lượng, tôi dần nhận ra rằng bản chất của các hiện tượng khí tượng là phi tuyến và phụ thuộc ngưỡng, trong đó các tín hiệu chỉ bộc lộ khi xem xét tương tác giữa nhiều biến. Việc chuyển dịch sang phân tích đa biến, sử dụng các biểu đồ nhiệt và các biến tương tác trong hồi quy logistic, đã giúp tôi giải mã được những cấu trúc ẩn mà các phương pháp tuyến tính không thể phát hiện."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb784860",
   "metadata": {},
   "source": [
    "#### **Learning & Growth**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95035d4f",
   "metadata": {},
   "source": [
    "Bài học tôi đạt được từ bước Data Exploration là nhận thức sâu sắc rằng đây không chỉ là một bước \"xem dữ liệu\" mang tính thủ tục, mà là nền tảng quyết định toàn bộ hướng đi của phân tích sau này. Việc rà soát có hệ thống cấu trúc bộ dữ liệu — từ số lượng quan sát, ý nghĩa của từng dòng dữ liệu, đến vai trò và định nghĩa của từng biến — giúp tôi hiểu rõ \"đơn vị phân tích\" mà mình đang làm việc, qua đó tránh được các diễn giải sai về mặt ngữ nghĩa. Thông qua kiểm tra tính toàn vẹn dữ liệu, tôi học được cách đưa ra các quyết định có cơ sở khoa học về việc xử lý trùng lặp, dữ liệu rỗng, cũng như phân biệt giữa giá trị thiếu thực sự và các giá trị thay thế mang tính quy ước. Phân tích phân phối của các biến số liên tục và biến phân loại giúp tôi nhận ra rằng các chỉ số như trung bình hay tương quan chỉ có ý nghĩa khi được đặt trong bối cảnh phân phối, độ lệch và sự mất cân bằng của dữ liệu. Đặc biệt, việc trực quan hóa dữ liệu và phân tích mẫu hình thiếu hụt (missingness patterns) đã giúp tôi hiểu rằng dữ liệu thiếu không phải lúc nào cũng là \"nhiễu\" cần loại bỏ, mà đôi khi phản ánh cấu trúc thu thập dữ liệu hoặc đặc trưng của hiện tượng tự nhiên. Từ đó, tôi rút ra bài học cốt lõi rằng Data Exploration không chỉ nhằm phát hiện lỗi, mà còn là quá trình hình thành giả thuyết, định hình câu hỏi nghiên cứu và thiết kế chiến lược tiền xử lý phù hợp. Đây chính là bước chuyển từ việc \"nhìn dữ liệu\" sang \"hiểu dữ liệu\", và là kỹ năng nền tảng nhưng mang tính quyết định đối với mọi phân tích khoa học dữ liệu nghiêm túc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7318d3d4",
   "metadata": {},
   "source": [
    "Quá trình giải quyết Câu hỏi nghiên cứu 1 đã trang bị cho tôi một nền tảng vững chắc về tư duy phân tầng dữ liệu (data stratification) và kỹ thuật xây dựng đặc trưng dựa trên cơ chế vật lý (physics-based feature engineering). Tôi học được rằng trong các bộ dữ liệu không gian – thời gian, ngữ cảnh không phải là yếu tố phụ trợ mà là điều kiện tiên quyết để diễn giải đúng tín hiệu. Việc chuyển đổi các biến thô (áp suất lúc 9am và 3pm) thành một biến cơ chế có ý nghĩa vật lý ($\\Delta P$), kết hợp với việc chuẩn hóa theo mùa vụ đặc thù của Nam Bán cầu, đã cho tôi thấy sức mạnh thực sự của việc tích hợp kiến thức miền (domain knowledge) vào phân tích dữ liệu. Song song đó, tôi phát triển kỹ năng trực quan hóa đa chiều, đặc biệt thông qua các bản đồ nhiệt tương tác, như một công cụ khám phá để phát hiện các ngưỡng phi tuyến và cấu trúc điều kiện mà các chỉ số thống kê đơn biến không thể nắm bắt.\n",
    "\n",
    "Một bài học mang tính bước ngoặt đến từ việc nhận diện vai trò \"người gác cổng\" của độ ẩm trong cơ chế phát sinh mưa. Kết quả cho thấy rằng tại các vùng khô hạn như sa mạc hoặc đồng cỏ, ngay cả khi tồn tại tín hiệu động lực mạnh (áp suất giảm sâu), mưa vẫn không xảy ra nếu độ ẩm không đạt đến một ngưỡng tới hạn. Phát hiện này đã thay đổi căn bản cách tôi nhìn nhận các biến khí tượng: chúng không hoạt động độc lập mà tương tác như một hệ sinh thái, trong đó tác động của mỗi biến phụ thuộc chặt chẽ vào trạng thái của các biến còn lại. Nhận thức này buộc tôi phải từ bỏ tư duy tuyến tính và chuyển sang tiếp cận phân tích theo điều kiện và tương tác.\n",
    "\n",
    "Ở cấp độ phát triển nghề nghiệp, dự án giúp tôi hình thành một tầm nhìn thực tế hơn về vai trò của một nhà khoa học dữ liệu. Tôi nhận ra rằng một Data Scientist giỏi không né tránh những công việc \"thủ công\" như tra cứu bản đồ địa lý, đối chiếu tài liệu khí hậu học hay thiết kế chiến lược tiền xử lý tỉ mỉ. Ngược lại, chính những bước chuẩn bị tưởng chừng không hào nhoáng này mới là yếu tố quyết định chất lượng của insight cuối cùng, chứ không phải độ phức tạp của thuật toán hay mô hình được sử dụng. Đồ án này đánh dấu một bước chuyển quan trọng trong tư duy của tôi: từ việc tập trung đơn thuần vào hiệu năng mô hình sang ưu tiên sự thấu hiểu bản chất dữ liệu và cơ chế sinh dữ liệu.\n",
    "\n",
    "Về mặt kỹ năng chuyên môn, tôi tích lũy được kinh nghiệm thực tiễn trong việc xây dựng các đặc trưng nâng cao và chuẩn hóa theo ngữ cảnh, bao gồm chuẩn hóa Z-score theo nhóm, chuẩn hóa bền vững cho dữ liệu có phân phối lệch, cũng như sử dụng kiểm định giả thuyết để xác nhận và củng cố các quan sát trực quan. Một bài học then chốt rút ra là các mô hình “một công thức cho mọi trường hợp” hiếm khi phù hợp với các hệ thống tự nhiên phức tạp; thay vào đó, các cách tiếp cận thích ứng theo vùng và theo bối cảnh mới phản ánh đúng thực tế vật lý.\n",
    "\n",
    "Cuối cùng, một phát hiện phản trực giác nhưng có tác động sâu sắc đến nhận thức của tôi là \"nghịch lý vùng nội địa\" trong Câu hỏi 4, nơi môi trường khô hạn không làm suy yếu mà ngược lại còn làm nổi bật giá trị dự báo của tín hiệu gió. Kết quả này nhấn mạnh rằng dữ liệu thực tế thường ẩn chứa những cơ chế không hiển nhiên và chỉ có thể được phát hiện khi đặt câu hỏi đúng trong bối cảnh phù hợp. Từ đó, tôi nhận ra rằng khoa học dữ liệu không chỉ là việc vận dụng các thư viện hay thuật toán có sẵn, mà là quá trình kết hợp chặt chẽ giữa kiến thức miền, tư duy thống kê và khả năng lập luận nhân quả. Chính sự kết hợp này cho phép biến các tập dữ liệu phức tạp thành những hiểu biết có ý nghĩa, hỗ trợ ra quyết định và tạo ra giá trị thực tiễn lâu dài."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da8899d",
   "metadata": {},
   "source": [
    "### **Võ Trần Duy Hoàng**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7d560",
   "metadata": {},
   "source": [
    "#### **Challenges & Difficulties Encountered**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1a5d5e",
   "metadata": {},
   "source": [
    "Trong quá trình thực hiện đồ án, tôi đã đối mặt với ba thử thách lớn về kỹ thuật, phân tích và tư duy hệ thống.\n",
    "\n",
    "Đầu tiên, rào cản về kỹ thuật nằm ở sự mất cân bằng dữ liệu. Đây cũng là thử thách đầu tiên và lớn nhất, thể hiện ở sự chênh lệch quá lớn giữa số ngày nắng (chiếm ~78%) và số ngày mưa (chỉ ~22%). Điều này khiến các mô hình ban đầu có xu hướng \"học vẹt\" và dự báo mọi ngày đều không mưa để đạt được độ chính xác (Accuracy) cao nhưng vô nghĩa, trong khi mục tiêu cốt lõi của chúng ta là tìm ra những cơn mưa hiếm hoi đó.\n",
    "\n",
    "Tiếp theo là rào cản về phân tích, nằm ở dữ liệu có độ băm cao và đa cộng tuyến: Biến địa lý (Location) với 49 địa điểm khác nhau tạo ra một bài toán khó về mã hóa. Nếu dùng phương pháp thông thường, dữ liệu sẽ trở nên cực kỳ cồng kềnh. Đồng thời, các biến khí tượng như `Temp9am` và `MaxTemp` lại có mối tương quan quá mạnh (Multicollinearity), gây nhiễu cho các thuật toán hồi quy và làm sai lệch trọng số của mô hình.\n",
    "\n",
    "Cuối cùng là rào cản cho tư duy hệ thống thể hiện qua sự thất bại của kỹ thuật PCA (Principal Component Analysis). Vốn dĩ, việc sử dụng PCA với kỳ vọng sẽ tinh gọn được bộ dữ liệu nhưng thực tế lại mang lại hệ quả làm mất đi ý nghĩa vật lý của các biến số sau khi nén đã khiến mô hình không thể giải thích được logic khí tượng, dẫn đến hiệu suất sụt giảm nghiêm trọng.\n",
    "\n",
    "Để vượt qua những rào cản này, tôi đã áp dụng 1 số chiến lược sau cho dữ liệu khí tượng, có thể đến như là việc giải quyết mất cân bằng bằng trọng số (Cost-sensitive Learning) bằng cách can thiệp vào hàm mất mát bằng tham số scale_pos_weight trong XGBoost, buộc mô hình phải trả giá đắt hơn nếu bỏ lỡ một cơn mưa, từ đó đẩy chỉ số Recall lên mức kỳ vọng; hay kỹ thuật hóa đặc trưng dựa trên logic vật lý thông qua việc thay vì dựa vào các thuật toán tự động giảm chiều thì tôi đã tự xây dựng các biến chênh lệch (Delta features) là `PressureChange` và `HumidityChange` nhằm chuyển đổi các con số vô nghĩa thành các tín hiệu động, giúp mô hình nắm bắt được xu hướng di chuyển của các khối khí; và thay One-Hot Encoding bằng Target Encoding cho cột `Location` giúp cho không chỉ giữ cho dữ liệu gọn nhẹ mà còn trực tiếp đưa 1 chỉ số rủi ro cho từng vùng địa phương vào mô hình.\n",
    "\n",
    "Dù vậy, điều khó khăn nhất trong toàn bộ dự án không nằm ở việc viết code, mà nằm ở việc giải mã kết quả của Random Forest. Qua quan sát tôi nhận thấy một mô hình có khả năng phân loại rất tốt này (AUC-ROC 0.887) nhưng lại có Recall thấp kỷ lục (0.483), qua việc hiểu được rằng Random Forest đang bị nén xác suất do áp đảo từ lớp đa số và nó tỏ ra cực kỳ thận trọng ở ngưỡng 0.5 là một bước ngoặt về tư duy của tôi trong việc nhận định ra tính chất ẩn giấu sâu bên trong bản chất của học máy. Và tôi còn phải học cách nhìn xuyên qua các con số thống kê để thấy được sự đánh đổi (Trade-off) giữa Precision và Recall. Tóm lại, thách thức này ở một độ khó cao hơn tất cả vì nó đòi hỏi sự kết hợp giữa hiểu biết sâu về thuật toán và khả năng phân tích logic xác suất, thay vì chỉ đơn giản là tối ưu hóa mã nguồn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090f3bd0",
   "metadata": {},
   "source": [
    "#### **Learning & Growth**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbc91b5",
   "metadata": {},
   "source": [
    "Về mặt kỹ năng kỹ thuật, tôi đã làm chủ được quy trình xây dựng mô hình học máy toàn diện: từ việc xử lý các tập dữ liệu lớn, mất cân bằng, đến việc triển khai các thuật toán phức tạp như XGBoost, Random Forest và Logistic Regression. Tôi đã hiểu sâu sắc cách tinh chỉnh các siêu tham số (Hyperparameters) không chỉ để đạt điểm số cao, mà để điều hướng mô hình theo mục tiêu cụ thể, chẳng hạn như sử dụng `scale_pos_weight` để ưu tiên chỉ số Recall.\n",
    "\n",
    "Về tư duy phân tích, bài học lớn nhất chính là sự chuyển dịch từ việc sử dụng dữ liệu thô sang xây dựng các yếu tố Feature Engineering. Tôi nhận ra rằng việc tạo ra các biến chênh lệch (Delta features) như `PressureChange` hay `HumidityChange` có giá trị gấp nhiều lần so với các chỉ số tĩnh, bởi chúng phản ánh đúng bản chất vận động của tự nhiên. Bên cạnh đó, việc áp dụng kỹ thuật Target Encoding cho biến `Location` đã giúp tôi hiểu cách giải quyết bài toán dữ liệu phân loại có độ băm cao (High Cardinality) một cách tinh tế mà không làm bùng nổ chiều dữ liệu.\n",
    "\n",
    "Về kiến thức chuyên ngành (Domain Knowledge), tôi đã nắm được phần nào các tín hiệu từ bầu khí quyển: sự sụt giảm áp suất báo hiệu bão, mối quan hệ nghịch biến giữa số giờ nắng và khả năng mưa, hay tầm quan trọng đặc biệt của các phép đo buổi chiều (3pm) so với buổi sáng.\n",
    "\n",
    "Một điều gây bất ngờ tôi thấy được qua đồ án này nằm ở nghịch lí khi xây dựng mô hình Random Forest, bởi một mô hình có khả năng phân loại xuất sắc (AUC-ROC lên tới 0.887) nhưng lại có độ hiệu quả vô cùng thấp ở chỉ số Recall (0.483). Hiện tượng này đã mở ra một góc nhìn hoàn toàn mới của tôi đối với ngưỡng quyết định (Decision Threshold). Nó cho tôi thấy rằng một mô hình tốt về mặt toán học vẫn có thể trở nên không hiệu quả trong thực tế nếu nó quá thận trọng và không được hiệu chỉnh ngưỡng phù hợp với bài toán rủi ro. Một bất ngờ khác là sự thất thế của PCA trong bài toán này. Ban đầu, tôi từng nghĩ việc giảm chiều dữ liệu bằng toán học sẽ giúp mô hình hiệu quả hơn. Nhưng thực tế đã chứng minh điều ngược lại rằng trong khoa học dữ liệu, những đặc trưng gốc được kỹ thuật hóa dựa trên logic vật lý luôn mang lại tín hiệu mạnh mẽ nhất, đem lại ý nghĩa nhất.\n",
    "\n",
    "Đồ án này còn tái định nghĩa hoàn toàn hiểu biết của tôi về Khoa học dữ liệu. Trước đây, tôi từng coi Data Science là việc tìm kiếm thuật toán mạnh nhất hoặc mới nhất, nhưng thực tế lại khác xa: Dữ liệu là gốc, mô hình cũng chỉ là phần ngọn, và thành công của mô hình không nằm ở việc chọn XGBoost hay Neural Network, mà nằm ở bước tiền xử lí và Feature Engineering. Một bộ dữ liệu sạch và giàu thông tin lại nâng tầm một thuật toán vốn chỉ ở mức trung bình, nhưng một thuật toán tối uu nhất cũng không thể xử lý được dữ liệu nhiễu.\n",
    "\n",
    "Bên cạnh đó, việc tập trung vào chỉ số đo lường nào cũng là một yếu tố quyết định: Chỉ số Accuracy không mang lại bất kì giá trị gì trong dự báo thiên tai mà thay vào đó Recall mới là thước đo chuẩn mực để đánh giá chính xác. Và việc thấu hiểu sự đánh đổi giữa Precision và Recall còn giúp tôi đưa ra những quyết định có tác động thực sự đến đời sống.\n",
    "\n",
    "Tóm lại, Khoa học dữ liệu là sự kết hợp giữa Nghệ thuật và Khoa học: Khoa học nằm ở toán học và code, nhưng nghệ thuật nằm ở cách chúng ta đặt câu hỏi nghiên cứu và lồng ghép logic vật lý vào mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c8c3c",
   "metadata": {},
   "source": [
    "### **Trần Đình Thi**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5888b174",
   "metadata": {},
   "source": [
    "#### **Challenges & Difficulties Encountered**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503752d",
   "metadata": {},
   "source": [
    "- Specific Obstacles: \n",
    "    - Technical: Xử lý tỷ lệ dữ liệu khuyết thiếu khổng lồ (hơn 40% ở biến Sunshine). Ban đầu tôi định xóa bỏ, nhưng sau đó nhận thấy việc này làm hỏng tính mùa vụ của dữ liệu.\n",
    "\n",
    "    - Analytical: Đối mặt với bài toán giảm chiều dữ liệu. Khi áp dụng PCA để tối ưu tốc độ, chỉ số Recall và F1-score sụt giảm nghiêm trọng, gây khó khăn trong việc cân bằng giữa hiệu suất tính toán và độ chính xác của mô hình.\n",
    "\n",
    "- How I overcame them: \n",
    "    - Tôi đã áp dụng Missing Indicator Flags để biến \"sự trống trải\" của dữ liệu thành một tính năng có nghĩa.\n",
    "\n",
    "    - Về vấn đề PCA, sau khi đánh giá lại, nhóm đã quyết định giữ lại các biến gốc (hoặc thực hiện Feature Selection thủ công) thay vì dùng PCA để bảo toàn các tín hiệu dự báo quan trọng nhất cho lớp dữ liệu \"Mưa\".\n",
    "\n",
    "- Most challenging & Why: Việc xây dựng cấu trúc Modular (thư mục src/). Đây là lần đầu tôi tách code từ Notebook ra các file .py. Việc quản lý đường dẫn và đảm bảo các module data_processing.py hay visualization.py hoạt động trơn tru trong mọi Notebook là một thử thách lớn về tư duy lập trình hệ thống."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc266100",
   "metadata": {},
   "source": [
    "#### **Learning & Growth**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2c88c",
   "metadata": {},
   "source": [
    "- What I have learned: \n",
    "    - Technical skills: Thành thạo kỹ thuật điền dữ liệu nâng cao MICE và cách đánh giá mô hình qua các chỉ số Recall/F1 thay vì chỉ nhìn vào Accuracy.\n",
    "\n",
    "    - Domain knowledge: Hiểu sâu về mối liên hệ giữa nhiệt độ, áp suất và độ ẩm – những \"ngòi nổ\" vật lý thực sự của khí hậu Úc.\n",
    "\n",
    "- What surprised me most: Tôi rất bất ngờ khi thấy các kỹ thuật \"cao siêu\" như PCA không phải lúc nào cũng mang lại kết quả tốt. Đôi khi việc hiểu rõ bản chất dữ liệu (Domain Knowledge) và giữ lại các đặc trưng gốc lại quan trọng hơn việc áp dụng các thuật toán phức tạp.\n",
    "\n",
    "- How has this project shaped your understanding of data science? Dự án này dạy tôi rằng Data Science là một quá trình thử nghiệm và sai (trial and error). Không có \"cây đũa thần\" nào cho mọi bộ dữ liệu. Một Data Scientist giỏi không phải là người dùng nhiều thuật toán nhất, mà là người biết chọn kỹ thuật phù hợp và dám từ bỏ những thứ không hiệu quả (như cách tôi đã từ bỏ PCA) để bảo vệ độ chính xác của mô hình."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
